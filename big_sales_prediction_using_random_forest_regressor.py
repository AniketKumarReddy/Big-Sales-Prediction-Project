# -*- coding: utf-8 -*-
"""Big Sales Prediction using Random Forest Regressor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18IFjZwn-WhEpDliqfu6BQhnHrPeSFJu9

# **Big Sales Prediction using Random Forest Regessor**

-------------

## **Objective**

The primary objective of this project is to develop and implement a predictive model using the Random Forest Regressor algorithm to accurately forecast future sales figures based on historical sales data and relevant features. By leveraging the power of ensemble learning and the Random Forest technique, the project aims to:

1. **Analyze and Preprocess Data:** Clean, preprocess, and analyze historical sales data to identify key features that significantly influence sales outcomes.

2. **Build a Random Forest Regressor Model:** Train a Random Forest Regressor model on the processed data to predict future sales, optimizing model parameters to improve accuracy and generalizability.

3. **Evaluate Model Performance:** Assess the model's performance using appropriate metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared, and compare it against baseline models or alternative regression techniques.

4. **Provide Actionable Insights:** Generate actionable insights and recommendations based on the modelâ€™s predictions to support strategic business decisions and optimize sales strategies.

5. **Enhance Predictive Accuracy:** Continuously refine the model by incorporating new data and exploring advanced techniques to improve prediction accuracy and adapt to evolving market conditions.

This project aims to enable businesses to make data-driven decisions, optimize sales forecasting, and ultimately drive growth and profitability.

## **Data Source**

# **Data Source ybi Foundation github "Big Sales Data"**
# Link =>https://github.com/YBI-Foundation/Dataset/blob/main/Big%20Sales%20Data.csv

## **Import Library**
"""

import pandas as pd
import numpy as np

"""## **Import Data**"""

df = pd.read_csv('https://github.com/YBI-Foundation/Dataset/raw/main/Big%20Sales%20Data.csv')

"""## **Describe Data**"""

df.head()

df.info()

df.describe()

df.columns

df.shape

df['Item_Weight'].fillna(df.groupby(['Item_Type'])['Item_Weight'].transform('mean'), inplace=True)

df.info()

df.describe()

"""## **Data Visualization**"""

import seaborn as sns
sns.pairplot(df)

"""## **Data Preprocessing**"""

df[['Item_Identifier']].value_counts()

df[['Item_Fat_Content']].value_counts()

df.replace({'Item_Fat_Content': {'low fat':'Low Fat', 'LF':'Low Fat', 'reg':'Regular'}}, inplace=True)

df[['Item_Fat_Content']].value_counts()

df.replace({'Item_Fat_Content' : {'Low Fat' : 0, 'Regular' : 1}}, inplace=True)

df[['Item_Type']].value_counts()

df.replace({'Item_Type':{'Fruits and Vegetables' :0,'Snack Foods' :0,'Household' :1,
                         'Frozen Foods' :0,'Dairy' :0,'Baking Goods' :0,'Canned' :0,
                         'Health and Hygiene' :1,'Meat' :0,'Soft Drinks' :0,'Breads' :0,
                         'Hard Drinks' :0,'Breakfast' :0,'Others' :2,
                         'Starchy Foods' :0, 'Breakfast' :0,'Seafood' :0}},inplace=True)

df[['Item_Type']].value_counts()

df[['Outlet_Identifier']].value_counts()

df.replace({'Outlet_Identifier':{'OUT027' : 0, 'OUT013' : 1,'OUT049' : 2, 'OUT046' : 3, 'OUT035' : 4,
                                 'OUT045' : 5, 'OUT018' : 6, 'OUT017' : 7, 'OUT010' : 8, 'OUT019' : 9}},inplace=True)

df[['Outlet_Identifier']].value_counts()

df[['Outlet_Size']].value_counts()

df.replace({'Outlet_Size':{'Small' : 0, 'Medium' : 1, 'High' : 2}},inplace=True)

df[['Outlet_Size']].value_counts()

df[['Outlet_Location_Type']].value_counts()

df.replace({'Outlet_Location_Type':{'Tier 1' : 0, 'Tier 2' : 1, 'Tier 3' : 2}},inplace=True)

df[['Outlet_Location_Type']].value_counts()

df[['Outlet_Type']].value_counts()

df.replace({'Outlet_Type':{'Grocery Store' : 0, 'Supermarket Type1' : 1, 'Supermarket Type2' : 2, 'Supermarket Type3' : 3}},inplace=True)

df[['Outlet_Type']].value_counts()

df.head()

df.info()

df.shape

"""## **Define Target Variable (y) and Feature Variables (X)**"""

y = df['Item_Outlet_Sales']

y.shape

y

X = df[['Item_Weight', 'Item_Fat_Content', 'Item_Visibility',
        'Item_Type', 'Item_MRP', 'Outlet_Identifier', 'Outlet_Establishment_Year',
        'Outlet_Size', 'Outlet_Location_Type',
        'Outlet_Type']]

X = df.drop(['Item_Identifier', 'Item_Outlet_Sales'], axis=1)

X.shape

X

from sklearn.preprocessing import StandardScaler

sc = StandardScaler()

X_std = df[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']]

X_std = sc.fit_transform(X_std)

X_std

X[['Item_weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']] = pd.DataFrame(X_std,columns= [['Item_weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']])

X

"""## **Train Test Split**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2529)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""## **Modeling**"""

from sklearn.ensemble import RandomForestRegressor

rfr = RandomForestRegressor(random_state=2529)

rfr.fit(X_train, y_train)

"""## **Model Evaluation**"""

y_pred = rfr.predict(X_test)

y_pred.shape

y_pred

"""## **Prediction**"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

mean_squared_error(y_test, y_pred)

mean_absolute_error(y_test, y_pred)

r2_score(y_test, y_pred)

import matplotlib.pyplot as plt
plt.scatter(y_test, y_pred)
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted')
plt.show()

"""## **Explaination**

# Big Sales Prediction using a Random Forest Regressor involves using a machine learning model to forecast future sales based on historical data. The Random Forest Regressor is an ensemble learning technique that builds multiple decision trees and combines their outputs to improve prediction accuracy. Here's a brief rundown:

# Data Collection: Gather historical sales data and relevant features (e.g., seasonality, promotions, economic indicators).

# Feature Selection: Identify and select features that are likely to influence sales.

# Training: Train the Random Forest Regressor using historical data. The model creates multiple decision trees, each trained on different subsets of the data, and combines their predictions.

# Prediction: Use the trained model to predict future sales based on new input data.

# Evaluation: Assess the model's performance using metrics like Mean Absolute Error or Root Mean Squared Error to ensure its accuracy.

# Random Forest helps in handling complex data patterns and interactions by averaging predictions from multiple trees, which often results in more reliable and robust forecasts.
"""